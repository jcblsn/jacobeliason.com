{
  "hash": "4edd68b19f44b8cda412e69c4745c3d9",
  "result": {
    "markdown": "---\ntitle: \"Preparing data from Strava for analysis\"\nauthor: 'Jacob Eliason' \ndate: '2021-04-30'\ncategories: [R, Sports]\ndescription: \"A process description of how I clean data collected from my runs.\"\n---\n\n::: {.cell}\n\n:::\n\n\nWhen I run, I use [Strava](https://www.strava.com/) to log my activity. In honor of recently running my one-thousandth mile on Strava, I thought I'd do a write up for the steps I use to process my user data in R. The data Strava makes available is granular and can be used for all kinds of fun things after the steps detailed here.\n\n![](2021-04-30-processing-strava-data-nyc.png)\n\n## 1. Export your data {#s1}\n\nPer the [instructions](https://support.strava.com/hc/en-us/articles/216918437-Exporting-your-Data-and-Bulk-Export) on their website, you can export your Strava activity data by navigating to your profile in a web browser and following *Settings* \\> *My Account* \\> *Download or Delete your Account - Get Started* \\> *Request Your Archive*. From that point, it takes me about 10 minutes to see a download link in my inbox.\n\nThe download apparently includes a lot of different kinds of data but the most salient (for my account, anyway) are contained in `activities.csv` and the `activities/` directory. The former contains summary information for each of my Strava activities and the latter contains individual files, each of which have second-to-second position data for an individual run, hike, or bike ride. The activity files appear to be some kind of custom or proprietary exercise file type--the two extensions I notice are `.gpx` and `.fit.gz`. At first glance, I don't recognize either.\n\nFortunately, as usual I find that someone else has already done the heavy lifting for the most important part of this process. The Github packages [`FITfileR`](https://github.com/grimbough/FITfileR) and [`trackeR`](https://github.com/trackerproject/trackeR) can be used to convert these file types into something more legible. Special thanks to [Mike Smith](https://github.com/grimbough) for his excellent work on the former.\n\n## 2. Unpacking `.gpx` and `.fit.gz` files {#s2}\n\nI start by installing the Github packages and loading those along with the `tidyverse`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# devtools::install_github(\"grimbough/FITfileR\")\n# devtools::install_github(\"trackerproject/trackeR\")\n\nlibrary(FITfileR)\nlibrary(trackeR)\nlibrary(tidyverse)\n```\n:::\n\n\nA few more lines help with setup and prepare for reading the activity files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPATH <- str_c(str_remove(getwd(),\"/jacobeliason.com/posts/2021-04-30-processing-data-from-strava\"),\"/personal-projects/strava\")\nexport_date <- \"2021-04-29\"\nPATH_ACTIVITIES <- str_c(PATH, \"/DATA/\",export_date,\"/activities/\")\nactivity_names <- list.files(PATH_ACTIVITIES)\nsample(activity_names, 3) # check to make sure I got the correct file path\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3162985846.gpx\" \"3366567990.fit\" \"3337555997.gpx\"\n```\n:::\n:::\n\n\nAs I look at the file names, the first thing that becomes apparent is that I have some extra work to do as a result of my alternately using my phone and a Garmin watch to record activities. Those two devices produce the two different file extensions I observe and require different steps for unpacking.\n\n### Uncompressing and reading files from my fitness watch (`.fit.gz`) {#s2-read-fit}\n\nThe `.fit.gz` files are [compressed](https://en.wikipedia.org/wiki/Gzip) and need to be uncompressed to `.fit` before I can use the `FITfileR` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompressed_record_names <- activity_names[str_sub(activity_names,-6,-1) == \"fit.gz\"]\n\nfor(i in 1:length(compressed_record_names)){\n  R.utils::gunzip(\n    str_c(PATH_ACTIVITIES, compressed_record_names[i]),\n    remove = F\n  )\n}\n```\n:::\n\n\nHaving unzipped the files, I again collect names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nactivity_names <- list.files(PATH_ACTIVITIES)\nuncompressed_fit_names <- activity_names[str_sub(activity_names,-3,-1) == \"fit\"] # want exact match to .fit only, no .fit.gz\n```\n:::\n\n\nNow, using `FITfileR::records()`, I transform the files into tidy, rectangular datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist.fit <- list()\nfor(i in 1:length(uncompressed_fit_names)) {\n  record <- FITfileR::readFitFile(\n    str_c(PATH_ACTIVITIES, uncompressed_record_names[i])\n  ) %>% FITfileR::records()\n  \n  if(length(record) > 1) {\n    record <- record %>% bind_rows() %>% mutate(activity_id = i, filename = uncompressed_fit_names[i])\n  }\n  \n  list.fit[[i]] <- record\n}\nfit_records <- list.fit %>% bind_rows() %>% arrange(timestamp)\n```\n:::\n\n\n### Reading files recorded from my iPhone (`.gpx`) {#s2-read-gpx}\n\nI turn my attention back to the `.gpx` files. Fortunately, these files don't require much beyond a simple pass from the `trackeR` function. I do some additional housekeeping along the way, but this part is pretty straightforward.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngpx_names <- activity_names[str_sub(activity_names,-3,-1) == \"gpx\"]\n\nlist.gpx <- list()\nfor(i in 1:length(gpx_names)) {\n  record <- trackeR::readGPX(str_c(PATH_ACTIVITIES, gpx_names[i])) %>% \n    as_tibble() %>% \n    rename(\n      timestamp = time, \n      position_lat = latitude, \n      position_long = longitude, \n      cadence = cadence_running\n    )\n  list.gpx[[i]] <- record\n}\n```\n:::\n\n\n### Combine both record types {#s2-combine}\n\nI add my two datasets together and with that, I'm ready to Learn Things.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecords <- bind_rows(\n  fit_records,\n  list.gpx %>% bind_rows()\n) %>% arrange(timestamp)\n\n# colnames(records)\n# nrow(records)\n```\n:::\n\n\n### Straightening out the summary information in `activities.csv` {#s2-summary}\n\nOne last thing I'll do before I finish up is make some tweaks to the `activities.csv` file I got in my original download. There's a surprising number of columns; it's kind of unwieldy when you first open it up. Here's a taste of what's in there.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nactivities <- read_csv(str_c(PATH, \"/DATA/\",export_date,\"/\",\"activities.csv\"))\n\ndim(activities)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 250  78\n```\n:::\n\n```{.r .cell-code}\nactivities %>% colnames() %>% sample(., 10, F) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Other Time\"                \"Cloud Cover\"              \n [3] \"Elevation Gain\"            \"Activity Name\"            \n [5] \"Number of Runs\"            \"Humidity\"                 \n [7] \"Prefer Perceived Exertion\" \"Weather Observation Time\" \n [9] \"Distance...16\"             \"Average Negative Grade\"   \n```\n:::\n:::\n\n\nI make some changes to the column names and order to taste, and I remove rows with empty file names. It turns out that those correspond with activities with no associated GPS data, such as treadmill or weightlifting workouts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecord_key_raw <- \n  activities %>% \n  janitor::clean_names() %>% # helper function for column names\n  janitor::remove_empty() %>% # drop empty rows\n  select(filename, everything()) %>% # reorder columns\n  filter(!is.na(filename)) # drop rows with empty file names\n```\n:::\n\n\nI also make a variety of mostly trivial changes for my own convenience and then I'm good to go!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nKM_TO_MI <- 0.621371\nM_TO_FT <- 3.28084\n\nrecord_key <- record_key_raw %>% \n  \n  # change units for elevation variables\n  mutate_at(vars(contains(\"elevation\")), function(x){x <- x*M_TO_FT}) %>% \n  mutate(\n    \n  # units #\n    distance = distance*KM_TO_MI,\n    duration = elapsed_time/60,\n    duration_moving = moving_time/60,\n    pace = (duration/distance) %>% round(2),\n    pace_moving = (duration_moving/distance) %>% round(2),\n    \n  # ids #\n    filename = filename %>% str_remove(., \"activities/\") %>% str_replace(., \"fit.gz\", \"fit\"),\n    activity_id = as.character(activity_id),\n    activity_type = tolower(activity_type),\n    \n  # incorrectly coded activities #\n    activity_type = ifelse(filename == \"1812636545.gpx\", \"hike\", activity_type), \n    activity_type = ifelse(filename == \"3324264305.fit\", \"walk\", activity_type), \n    \n    \n  # dates #\n    rdatetime_utc = lubridate::as_datetime(activity_date, format = \"%b %d, %Y, %I:%M:%S %p\", tz = \"UTC\"),\n    rdatetime_et = lubridate::as_datetime(rdatetime_utc, tz = \"America/New_York\"),\n    rdate_et = lubridate::as_date(rdatetime_et), \n    \n    rday = lubridate::day(rdate_et),\n    rmonth = lubridate::month(rdate_et),\n    ryear = lubridate::year(rdate_et),\n    rhour_et = lubridate::hour(rdatetime_et),\n    rminute_et = lubridate::minute(rdatetime_et)\n\n  ) %>% \n  select( # drop empty variables\n    -contains(\"weather\"), -contains(\"precipitation\"), -contains(\"wind\"),\n    -apparent_temperature, -sunrise_time, -sunset_time, -dewpoint, -humidity, -cloud_cover, -uv_index\n  ) %>% \n  mutate_if(is.numeric, ~round(.x, 2)) # round numeric variables\n```\n:::\n\n\nNow, for each run, I have information on granular location data and summary information in datasets `records` and `record_key` respectively. The interesting stuff pretty much all comes after this point, but I'll save that for another post.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}