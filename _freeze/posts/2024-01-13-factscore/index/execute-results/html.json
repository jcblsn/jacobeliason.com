{
  "hash": "0530069e3dd3db6ca85f46af03da66eb",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Exploring FActScore, a tool for evaluating the factuality of LLM-generated text'\ndescription: Steps towards machine-assisted peer review\ncategories:\n  - llm\n  - factscore\n  - factuality\n  - deep learning\nauthor: Jacob Eliason\ndate: '2024-01-13'\ndraft: true\nbibliography:\n  - references.bib\ntable-of-contents: true\nformat:\n  html:\n    code-fold: show\n    code-overflow: wrap\n    code-tools: true\nexecute:\n  freeze: auto\n---\n\n```{r}\n#| echo: false\n\n# goal of this post is to provide working illustration of factscore paper using out of sample questions and give evaluation of unevaluated model\n\n# * determine corpus with title and text pairs\n#     * how to determine what questions will be used to evaluate comprehension of corpus?\n# * register custom knowledge source (possible to combine with wikipedia?)\n# * generate answers to questions, write in custom format\n# * run factscorer with chatgpt+retrieval and get_score\n```\n\n\n\n## Introduction\n\nI've been drawn lately towards an alternative frame for the current batch of applied deep learning tools—mostly LLMs—which now seem to be widely referred to as \"generative AI.\" I think a lot of people are hung up on \"intelligence\" in light of obvious shortcomings visible in, say, the free version of ChatGPT. \n\n{{}}\n\nI don't have a position on whether future iterations of this architecture will be genuinely \"intelligent\" or \"[reach AGI](https://openai.com/blog/planning-for-agi-and-beyond)\" in one year or five years or ever, but the case for existing models alone continuing to be substantially useful to people is pretty strong.\n\n\n{{< tweet karpathy 1744062845426532473 >}}\n\n\n\n\"Intelligence amplification\" feels useful. It's much easier to see how language models could help humans think and work better than it is to imagine this paradigm as a replacement or alternative to human intelligence.\n\nFor example, existing language models are prone to hallucinating and even state-of-the-art models are not reliable for the generation of factual text outside the discussion of very widely-known facts. ChatGPT is great for aquiring a baseline level of knowledge about a topic you're not familiar with, but its shortcomings are obvious as soon as you progress beyond basic questions. It's not obvious that this will change with the next generation of models based on the transformer architecture, as concerns about exhausting available training data have grown louder since Gemini's underwhelming launch.\n\n## FActScore\n\nFActScore is [] (@factscore).\n\n## Implementation\n\nit took a little bit of configuring\n- updates for recent versions of `openai` # https://community.openai.com/t/cannot-import-name-openai-from-openai/486147/3\n- modification to run on mac\n\n::: {#01329adf .cell execution_count=2}\n\n::: {.cell-output .cell-output-stderr}\n```\n[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/jacobeliason/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n```\n:::\n:::\n\n\n### Corpus\n\nmaybe use https://ipsur.org/index.html and do questions about stats\n\n### Test questions\n\n### Evaluation\n\n### Case study\n\n## Conclusion\n\nasdf\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}